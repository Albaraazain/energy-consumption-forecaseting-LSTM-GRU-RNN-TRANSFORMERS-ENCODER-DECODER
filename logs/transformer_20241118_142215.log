2024-11-18 14:22:15,877 - INFO - Starting training for TRANSFORMER model
2024-11-18 14:22:15,878 - INFO - Using device: cuda
2024-11-18 14:22:15,878 - INFO - Configuration: {'input_size': 1, 'dec_seq_len': 48, 'dim_val': 128, 'n_encoder_layers': 4, 'n_decoder_layers': 4, 'n_heads': 8, 'dropout_encoder': 0.2, 'dropout_decoder': 0.2, 'dropout_pos_enc': 0.1, 'dim_feedforward_encoder': 512, 'dim_feedforward_decoder': 512, 'num_predicted_features': 1, 'learning_rate': 0.0001, 'epochs': 100}
2024-11-18 14:22:16,020 - INFO - Data split - Train: 83347, Val: 17860, Test: 17861
2024-11-18 14:22:16,027 - INFO - DataLoaders created successfully
2024-11-18 14:22:16,027 - INFO - Data loaders created successfully
2024-11-18 14:22:17,026 - INFO - Model created successfully: Transformer
2024-11-18 14:22:17,026 - INFO - Number of parameters: 1860353
2024-11-18 14:22:18,032 - INFO - Starting training for transformer
2024-11-18 14:22:18,032 - INFO - Training on device: cuda
2024-11-18 14:22:18,264 - ERROR - Training error: query should be unbatched 2D or batched 3D tensor but received 4-D query tensor
2024-11-18 14:22:18,264 - INFO - Training completed in 0.23s
2024-11-18 14:22:18,798 - ERROR - Error during training: query should be unbatched 2D or batched 3D tensor but received 4-D query tensor
2024-11-18 14:22:18,841 - ERROR - Traceback:
Traceback (most recent call last):
  File "C:\Projects\GradProject\IoT-Based-Energy-Consumption-Prediction-Using-Transformers\utils\training_utils.py", line 239, in train
    train_loss = self._train_epoch()
  File "C:\Projects\GradProject\IoT-Based-Energy-Consumption-Prediction-Using-Transformers\utils\training_utils.py", line 160, in _train_epoch
    output, target = self._forward_step(batch)
  File "C:\Projects\GradProject\IoT-Based-Energy-Consumption-Prediction-Using-Transformers\utils\training_utils.py", line 142, in _forward_step
    output = self.model(src, tgt, src_mask, tgt_mask)
  File "C:\Users\Pc\.conda\envs\energy_pred\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\Pc\.conda\envs\energy_pred\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Projects\GradProject\IoT-Based-Energy-Consumption-Prediction-Using-Transformers\models\attention\transformer.py", line 222, in forward
    memory = self.encode(src, src_mask)
  File "C:\Projects\GradProject\IoT-Based-Energy-Consumption-Prediction-Using-Transformers\models\attention\transformer.py", line 185, in encode
    src = layer(src, src_mask)
  File "C:\Users\Pc\.conda\envs\energy_pred\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\Pc\.conda\envs\energy_pred\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Projects\GradProject\IoT-Based-Energy-Consumption-Prediction-Using-Transformers\models\attention\transformer.py", line 56, in forward
    src2, _ = self.self_attn(src2, src2, src2, attn_mask=src_mask)
  File "C:\Users\Pc\.conda\envs\energy_pred\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\Pc\.conda\envs\energy_pred\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Pc\.conda\envs\energy_pred\lib\site-packages\torch\nn\modules\activation.py", line 1275, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "C:\Users\Pc\.conda\envs\energy_pred\lib\site-packages\torch\nn\functional.py", line 5347, in multi_head_attention_forward
    is_batched = _mha_shape_check(query, key, value, key_padding_mask, attn_mask, num_heads)
  File "C:\Users\Pc\.conda\envs\energy_pred\lib\site-packages\torch\nn\functional.py", line 5171, in _mha_shape_check
    raise AssertionError(
AssertionError: query should be unbatched 2D or batched 3D tensor but received 4-D query tensor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Projects\GradProject\IoT-Based-Energy-Consumption-Prediction-Using-Transformers\train_models.py", line 151, in train_model
    trainer.train(
  File "C:\Projects\GradProject\IoT-Based-Energy-Consumption-Prediction-Using-Transformers\utils\training_utils.py", line 293, in train
    self.save_results()
  File "C:\Projects\GradProject\IoT-Based-Energy-Consumption-Prediction-Using-Transformers\utils\training_utils.py", line 371, in save_results
    self.plot_predictions()
  File "C:\Projects\GradProject\IoT-Based-Energy-Consumption-Prediction-Using-Transformers\utils\training_utils.py", line 424, in plot_predictions
    output, target = self._forward_step(batch)
  File "C:\Projects\GradProject\IoT-Based-Energy-Consumption-Prediction-Using-Transformers\utils\training_utils.py", line 142, in _forward_step
    output = self.model(src, tgt, src_mask, tgt_mask)
  File "C:\Users\Pc\.conda\envs\energy_pred\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\Pc\.conda\envs\energy_pred\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Projects\GradProject\IoT-Based-Energy-Consumption-Prediction-Using-Transformers\models\attention\transformer.py", line 222, in forward
    memory = self.encode(src, src_mask)
  File "C:\Projects\GradProject\IoT-Based-Energy-Consumption-Prediction-Using-Transformers\models\attention\transformer.py", line 185, in encode
    src = layer(src, src_mask)
  File "C:\Users\Pc\.conda\envs\energy_pred\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\Pc\.conda\envs\energy_pred\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Projects\GradProject\IoT-Based-Energy-Consumption-Prediction-Using-Transformers\models\attention\transformer.py", line 56, in forward
    src2, _ = self.self_attn(src2, src2, src2, attn_mask=src_mask)
  File "C:\Users\Pc\.conda\envs\energy_pred\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\Pc\.conda\envs\energy_pred\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Pc\.conda\envs\energy_pred\lib\site-packages\torch\nn\modules\activation.py", line 1275, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "C:\Users\Pc\.conda\envs\energy_pred\lib\site-packages\torch\nn\functional.py", line 5347, in multi_head_attention_forward
    is_batched = _mha_shape_check(query, key, value, key_padding_mask, attn_mask, num_heads)
  File "C:\Users\Pc\.conda\envs\energy_pred\lib\site-packages\torch\nn\functional.py", line 5171, in _mha_shape_check
    raise AssertionError(
AssertionError: query should be unbatched 2D or batched 3D tensor but received 4-D query tensor

